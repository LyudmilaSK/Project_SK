## Проект 6. Выбираем авто выгодно

## Задача
#### Построить модель определения цены автомобиля на вторичном рынке по основным характеристикам

## Проблема
#### Отсутствие истории продаж и актуальной информации о предложениях на рынке

## Основные инструменты
* #### [Авто.ру](https://auto.ru/)  
* #### [Библиотека scikit-learn](https://scikit-learn.org/stable/)  
* #### [Программная среда optuna](https://optuna.org/)  
* #### [Проэкт автоматизации браузеров Селениум](https://www.selenium.dev/) 
* #### [Пакет для анализа документов BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

## Выполнено
* #### Написан код для парсинга с помощью Selenium и BeautifulSoup  
* #### Приведение обучающей и тестовой выборки к единообразию  
* #### Учтена временная разница между выборками при адаптации цены на авто   
* #### Проанализированы полученные признаки  
* #### Заполнены пропуски  
* #### Проанализирована взаимосвязь признаков  
* #### Рассмотрены разные варианты удаления шума  
* #### Созданы новые параметры  
* #### Выбраны параметры для моделирования  
* #### Нормализованы некоторые признаки  
* #### Построена наивная модель  
* #### Протестирован CatBoost  
* #### Реализованы модели:  
     #### RandomForestRegressor  
     #### ExtraTreesRegressor  
     #### AdaBoostRegressor  
     #### GradientBoostingRegressor  
     #### HistGradientBoostingRegressor   
* #### Для трёх из пяти моделей оптимизированы гиперпараметры с помощью Optuna и SearchCV
* #### Построенные модели оценены с помощью метрики MAPE  
* #### Для лучших моделей выполнен стэкинг  

## Анализ результатов моделирования
* #### Разница между статистикой на валидации и на тесте возможно является причиной переобучения  
* #### Одной из лучших моделей является Случайный лес с параметрами по умолчанию, что возможно объясняется некачественными данными.  
* #### Последнее показывает необходимость дополнительных итераций по EDA и ML

## Проблемы при выполнении проекта
* #### Длительный парсинг (написанный код с помощью selenium затрачивал много времени на функцию get).
* #### В результате парсинга за 3 суток было прочитано лишь 9000 ссылок  
* #### Реализация парсинга в GoogleColab вызыавла ошибки при чтении XPath  
* #### Затраты времени на выполнение операций по подбору гиперпараметров  
* #### Обновление Kaggle после 20 минутного простоя и выполнение кода заново

## Точки роста
* #### Определение границ гиперпараметров при реализации SearchCV  
* #### Обработка текстовых признаков. Возможно это не поможет на данной выборке без дополнительного парсинга, так как много пропусков по текстовым данным.  
* #### Более эффективный Feature Engineering (формирование групп внутри определенных признаков, таких как модели, бренды и т.д.)  
* #### Эффективная по времени реализация парсинга  
* #### Валидация
